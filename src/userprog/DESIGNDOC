
		     +--------------------------+
         | CS 140	                  |
		     | PROJECT 2: USER PROGRAMS	|
		     | DESIGN DOCUMENT        	|
		     +--------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Andy Moreland <andymo@stanford.edu>
Alex Ryan <alexryan@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Describe briefly which parts of the assignment were implemented by
>> each member of your team. If some team members contributed significantly
>> more or less than others (e.g. 2x), indicate that here.

Andy Moreland: FS syscalls, arg passing, user memory access
Alex Ryan: Process control syscalls, process persistence

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			   ARGUMENT PASSING
			   ================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

From process.c: 
struct process_init_data {
  char *cmdline;
  ...
};

`cmdline` is used to hold a pointer to a malloced copy of the
full command line. We pass this struct as aux data to process_start.


---- ALGORITHMS ----

>> A2: Briefly describe how you implemented argument parsing.  How do
>> you arrange for the elements of argv[] to be in the right order?
>> How do you avoid overflowing the stack page?

We still copy the command line that is passed to us, but now we use malloc.

We parse out the first #FIXME: do this


---- RATIONALE ----

>> A3: Why does Pintos implement strtok_r() but not strtok()?

strtok's specification requires that the C library implementors maintain
some sort of state on every call to strtok. This makes me suspicious
of its thread safety and I wonder about how it manages memory. strtok_r
is cleaner in these regards, especially since we are programming a kernel
and care a lot about concurrency and memory.

FIXME: review this

>> A4: In Pintos, the kernel separates commands into a executable name
>> and arguments.  In Unix-like systems, the shell does this
>> separation.  Identify at least two advantages of the Unix approach.

The Unix approach allows multiple arg separation schemes to coexist --
for instance, the shell could choose to use the ';' character as an
arg separator if it wanted to.

To Unix approach also reduces the amount of vulnerable surface area of
the kernel. There is no need for the kernel to perform string manipula-
tion or do other complicated things that could potentially lead to stack
overflows.

Furthermore, Unix allows executables to contain spaces in their names,
if that is desired.

			     SYSTEM CALLS
			     ============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

process.c: 
This struct is used to store metadata that potentially lives on after
the associated process dies.

struct pdata {
  struct list_elem elem;
  int tid;
  struct lock monitor;
  struct semaphore dead_latch;
  int references;
  int process_return_val;
};

`elem` is used for membership in a thread's list of child processes
`tid` is used as an ID for lookups in the list of child processes
  from the perspective of the parent
`monitor` is a monitor lock that protects all of this struct's state
`dead_latch` is used to prevent `wait` from returning until the child
  exits.
`references` is used as a ref-count to prevent prematurely killing this
  struct.
`process_return_val` stores the return val of the this process when it
  dies.

syscall.c:

This struct is used to store metadata about opened files.

struct file_descriptor {
  struct list_elem elem;
  struct file *f;
  int fd_id;
};

`elem` is used for membership in a thread's file_descriptors list
`f` is a pointer to the associated file
`fd_id` is a process-unique id that is used for reference by 
  user code

thread.h:

struct thread:

The following members of thread are all used when a thread is a process.

struct list file_descriptors;
struct file *executable;
int highest_fd_id;      
struct list_elem child_elem;
struct list child_processes;
struct pdata *pdata;                
struct thread *parent_process;

`file_descriptors` is used to store a list of open file descriptors
  associated with the process.
`executable` pointer to the file that this process is running out of.
  We need a reference so that we can close the file when we terminate.
`highest_fd_id` is the highest_fd_id that has been allocated for this
  process so far. This allows us to not re-use fd_ids.
`child_elem` is used for membership in the child_processes list.
`child_processes` list of processes spawned (using exec) by this process.
`pdata` is a pointer to metadata for this process that might outlive it.
`parent_process` is a pointer to the process that spawned this one.


>> B2: Describe how file descriptors are associated with open files.
>> Are file descriptors unique within the entire OS or just within a
>> single process?

File descriptors are structs that are malloced. They are assigned an
integer ID that is passed to and returned from syscalls. Each
process maintains a list of file descriptors that it has opened and
iterates over this list in order to find the requested one.

The ids are only unique within a process.

---- ALGORITHMS ----

>> B3: Describe your code for reading and writing user data from the
>> kernel.

In order to look up the i'th arg, we offset from the passed esp
by sizeof(char *) * i. Then we verify that this address is valid before
dereferencing it, and if it is a buffer or string pointer then
we check that what it is pointing to is valid.

We have a few main functions that we use in order to verify addresses:

The main one is `verify_pointer`. It verifies that the pointer that it
is passed is in user space that has been mapped to a page this logic is
extracted out into `verify_address`. We also verify that
`verify_pointer_offset` for an offset of sizeof (void *) is valid.

`verify_pointer_offset` is intended for checking that all of the memory 
between the passed address and the given offset is correct. We check
the address at `pointer + offset` and `pointer + PGSIZE * i` for every
`pointer + PGSIZE * i` that is less than `pointer + offset`.

`verify_address` checks that the given address is in user memory and
that it is mapped to a page.

>> B4: Suppose a system call causes a full page (4,096 bytes) of data
>> to be copied from user space into the kernel.  What is the least
>> and the greatest possible number of inspections of the page table
>> (e.g. calls to pagedir_get_page()) that might result?  What about
>> for a system call that only copies 2 bytes of data?  Is there room
>> for improvement in these numbers, and how much?

In the 4096 case, the largest number that could occur is 3.
If the 4096 bytes cross (at most) one page, we will check the first
byte of the page boundary. We always check the start and end byte's
pages.

In the 2 byte case, we will also check at most 3, since we check
the start and end, and there is a possibly redundant call to
the check if the 2nd byte is over the page boundary, since
we treat it as a buffer and so check the first byte of every page
that is not the page of the start byte.

In general, if we span n pages, we will make n + 2 calls to 
pagedir_get_page. We could (in some cases) make this n + 1, as in the
2 byte case, because we could skip the redundant middle check. This
would significantly change how we factored our code, and only gain
a very small performance increase.

>> B5: Briefly describe your implementation of the "wait" system call
>> and how it interacts with process termination.

We implement wait by storing the processes' exit status in a struct
that is malloced externally from the thread struct. This block
lives until both the child and parent die -- at this point we no longer
are interested in the return information of the process.

In this block we have a semaphore that is initialized to 0 when
the process is created. When the child dies, it stores its return
value in the `pdata` block sema-ups, and then it 
decrements a reference count that is initialized to 2.

When the parent dies, it decrements the reference count also.
At any point, if the reference count reaches 0 we free the block.

Anyways, when the parent calls "wait", we sema-down on the pdata 
semaphore. This returns once the child process dies, or immediately
if it is already dead, and then we return the child's return
value to the caller.

Race conditions in this pdata struct are prevented by the use of a
monitor lock that protects all of its state.

FIXME: review this

>> B6: Any access to user program memory at a user-specified address
>> can fail due to a bad pointer value.  Such accesses must cause the
>> process to be terminated.  System calls are fraught with such
>> accesses, e.g. a "write" system call requires reading the system
>> call number from the user stack, then each of the call's three
>> arguments, then an arbitrary amount of user memory, and any of
>> these can fail at any point.  This poses a design and
>> error-handling problem: how do you best avoid obscuring the primary
>> function of code in a morass of error-handling?  Furthermore, when
>> an error is detected, how do you ensure that all temporarily
>> allocated resources (locks, buffers, etc.) are freed?  In a few
>> paragraphs, describe the strategy or strategies you adopted for
>> managing these issues.  Give an example.

We verify all arguments, buffers and strings are in valid user memory
before we use them. Since we know that we are operating in a single-
threaded process on a single-core machine, we know that if we are 
in a syscall once the syscall has validated these things they will
remain valid at least until we return.

We only allocate memory or locks after we have validated arguments.
Furthermore, it is baked into the cleanup process of a process that is
terminated that all memory or locks that syscalls allocate are 
cleaned up.

Thus, we minimize pointless resource allocation and always make sure
to clean up after ourselves.

As an example, if we `open` a file using valid arguments, our
syscall code will acquire a lock that protects the file system and then 
malloc a struct on the kernel's heap that it uses for housekeeping. If
the arguments were invalid, none of this will happen so we don't pointlessly
create anything that we need to clean up. If we then try to run a syscall
passing in a pointer to a buffer partly in kernel memory or unmapped user
memory, we will kill the thread and this execution flow leads us to
process_exit which iterates over all of the file_descriptor structs that
were opened and frees them. No locks could have been open at this point
since we make sure to acquire locks only once we decide we won't kill the
thread in that syscall.

So, we're completely tidy at this point. This is the general outline
that all of our code follows.


---- SYNCHRONIZATION ----

>> B7: The "exec" system call returns -1 if loading the new executable
>> fails, so it cannot return before the new executable has completed
>> loading.  How does your code ensure this?  How is the load
>> success/failure status passed back to the thread that calls "exec"?

FIXME: do this

>> B8: Consider parent process P with child process C.  How do you
>> ensure proper synchronization and avoid race conditions when P
>> calls wait(C) before C exits?  After C exits?  How do you ensure
>> that all resources are freed in each case?  How about when P
>> terminates without waiting, before C exits?  After C exits?  Are
>> there any special cases?

FIXME: do this

---- RATIONALE ----

>> B9: Why did you choose to implement access to user memory from the
>> kernel in the way that you did?

We decided to write out user memory access the way we did because
we wanted to make it as simple as possible. We felt that since this is
a toy operating system, efficiency is not as important and it's just
easier to bake the logic for handling invalid addresses into explicit
C code rather than relying on the MMU.

Also, we optimized our verification code fairly well, so (for instance)
we don't needlessly check every byte in a buffer; we just make sure
that every page that is referenced is mapped and that the start
and end of the buffer lie within user memory.

FIXME: review this

>> B10: What advantages or disadvantages can you see to your design
>> for file descriptors?

One major advantage that we have is that it is easy to tell if fd_id
that a user supplies to us is completely bogus. This is much harder
if an fd_id is literally a pointer to the file_descriptor data. But
this way we never dereference a pointer that points to a deallocated
file_descriptor block.

Also, if we wanted to we would be able to move where we stored the 
file_descriptor information.

On the other hand, we have a hard time distinguishing file descriptors
for different processes. If process `a` maps an FD to id 3, and process
`b` maps an FD to id 3, it is possible that if process b talks to a, 
`b` could mistakenly pass its file descriptor and have `a` try to use it
and not encounter an error.

If we had used globally uniqued fd_ids, this problem would be easy to 
solve, but then we would have to ensure that no races occurred in
incrementing this counter. We could have used gcc builtins in order
to do an atomic get and increment, but we felt that this was more
complicated than necessary.

>> B11: The default tid_t to pid_t mapping is the identity mapping.
>> If you changed it, what advantages are there to your approach?

We did not change this because in this system each process has one thread.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?

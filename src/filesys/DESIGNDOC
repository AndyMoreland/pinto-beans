       	 +-------------------------+
		     | CS 140                  |
		     | PROJECT 4: FILE SYSTEMS |
		     | DESIGN DOCUMENT         |
		     +-------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Alex Ryan <alexryan@stanford.edu>
Andy Moreland <andymo@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

We're doing something that feels a little sleazy by storing directory
locks and an is_directory bool on inodes. This is how linux does it,
though, so there is precedent :-).

>> Describe briefly which parts of the assignment were implemented by
>> each member of your team. If some team members contributed significantly
>> more or less than others (e.g. 2x), indicate that here.

Andy Moreland: all
Alex Ryan: all

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

		     INDEXED AND EXTENSIBLE FILES
		     ============================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

From inode.c:

struct inode_indirect_disk
  {
    block_sector_t ptrs[INDIRECT_CAP];
  };

This struct is used to represent a block of pointers to sectors that is
stored in disk in an indirect block.

struct inode_disk
  {
    off_t length;                       /* File size in bytes. */
    unsigned magic;                     /* Magic number. */
    struct 
      {
        block_sector_t direct[INODE_NUM_DIRECT];
        block_sector_t indirect[INODE_NUM_INDIRECT];
        block_sector_t dbl_indirect[INODE_NUM_DBL_INDIRECT];
      };
    bool is_dir;                      /* True if inode represents a directory. */
    uint32_t unused[0];               /* Not used. */
  };

`struct inode_disk` is the on-disk representation of an inode.

`length` is self-explanatory.
`magic` attempts to detect corruption.
`direct` is an array of direct block_sector numbers
`indirect` is an array of block_sectors of `inode_indirect_disk`s
`dbl_indirect` is an array of block_sectors of `inode_indirect_disks`
  of block sectors of `inode_indirect_disk`s
`is_dir is true if the inode stores a dir

struct inode 
  {
    struct list_elem elem;              /* Element in inode list. */
    block_sector_t sector;              /* Sector number of disk location. */
    int open_cnt;                       /* Number of openers. */
    bool removed;                       /* True if deleted, false otherwise. */
    int deny_write_cnt;                 /* 0: writes ok, >0: deny writes. */
    struct lock dir_lock;               /* If this inode represents a directory
                                           then this prevents concurent access. */
    struct lock metadata_lock;          /* Protects deny_write_cnt, open_cnt, etc. */
    struct lock extend_lock;            /* Held while inode is being extended. */
  };

`struct inode` is an in-memory inode. Most of its members are unchanged. 
The comments are self-explanatory. It does seem a little odd to have three
locks per inode, but dir_lock is specifically for directory-level operations,
metadata_lock is to coordinate file extensions and sector memory operations
(held for only very brief moments of time to atomically update `length' etc)
and the extend_lock is used to prevent multiple simultaneous file extensions.


>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.

We have 123 direct blocks of 512 bytes each,
1 indirect block capable of pointing to 128 blocks of 512 bytes each
1 dbly indirect pointing to 128 indirects pointing to 128 512 byte blocks

This adds up to 123 + 128 + 128*128 = 16635 blocks of 512 bytes each,
for a total of 8517120 bytes (or about 8.123 megabytes).


---- SYNCHRONIZATION ----

>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.

When an inode is going to be extended we hold an `extend_lock` on it that 
prevents anyone else from starting their extension. Once the lock is
acquired, we check the length of the file in order to make sure
that an extend needs to still be dnoe. (Note that the `extend_lock' is
not even touched on a non-extending write or any read, so this still
allows for very strong file concurrency.)

>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.

The code takes very explicit care to:
- (read) check file lengths before reading from any out-of-bounds sectors 
- (write) initialize file data before increasing file length

In this way, process A will never try to access an invalid, or partially-
initialized, block that B is going to work with. B only notifies A of
the sector's existence after it has been completely initialized.
(This system still allows for A to read sectors as they are written by
B, provided that B stays ahead of A. Once A exhausts B's current
written content, it will complete its read.)


>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.

The only blocking file operation that we support is an extending write,
and that blocks only other extending writes. That is, almost all file
operations proceed lockless, with only very minimal synchronization
code for housekeeping purposes that touches only a lock or two to
execute two statements.

In particular, the code that is executed while holding a lock is
fixed in runtime, rather than e.g. buffering large memory areas or
allowing for arbitrary process code to occur while holding any locks.


---- RATIONALE ----

>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?

The inode index design that we chose addresses a balance between 
possible file size and metadata overhead (both in size and runtime).
First of all, ditching the contiguous file format leads tremendous 
advantages to fragmentation and disk utilization, as files are free
to segment themselves to fit into any available regions of the disk,
rather than requiring for any specific available memory layout.

However, indirection leads to space overhead of the intermediary indirect
blocks as well as the cache expense, etc to actually traverse through
them to fetch sector numbers. To minimize this overhead, we used as many
direct pointers as possible so that small files will not be bloated
proportionally by this extra overhead; but we still need to support
8 megabyte files, so the single doubly-indirect block is used to
provide for the expansion potential of a file.

The cache in particular mitigates a lot of the computational overhead
of fetching entries from a doubly-indirect block, as most consecutive
file block reads will require very limited disk I/O for these indirect
blocks.

			    SUBDIRECTORIES
			    ==============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

from filesys.h:

struct filedir
  {
    union 
      {
        struct file *f;
        struct dir *d;
      };
    enum filedir_type mode;
  };

`struct filedir` is used in places where we can return either a file 
  or a dir, like filesys_open. Which thing it stores is indicated by `mode`.

enum filedir_type
  {
    FILE_DESCRIPTOR_FILE,
    FILE_DESCRIPTOR_DIR
  };

This enum is used by `struct filedir` in order to indicate if it is storing
  a reference to a file or a dir.

from syscall.c:

struct file_descriptor {
  struct list_elem elem;
  struct filedir *filedir; // this was changed 
  int fd_id;
};

`filedir` now stores either a file or dir. The structure that holds this
  is described above.

from thread.h in `struct thread`:

++ struct dir *working_directory;      

`working_directory` is an opened dir representing thread's working directory.


from inode.c in `struct inode`:

struct lock dir_lock;

`dir_lock` is a little weird.
It's acquired by directory.c in order to prevent concurrent directory
operations. We placed it here because inodes were shared between all
`struct dir`s associated with an inode.


---- ALGORITHMS ----

>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?

We begin a path traversal by finding the "base" directory of the path.
For relative paths this is the working directory, and for absolute paths
this is the root directory. Then we loop over each `strtok_r`'d token
in the path -- using '/' -- as our separator. We lookup each token
in our current directory, make sure it's a directory, and then set
that to be our new current directory. If we ever encounter a file
midway through our path traversal we bail out. 

The actual code is split into three functions -- one which finds the
base directory for a path, one which finds the "containing" directory
of a path (aka "/foo/bar/baz" has containing directory "bar") and one
which returns the inode of the target of a full path.

---- SYNCHRONIZATION ----

>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.

Once we `dir_open` a directory we will acquire its `directory_lock`
which is stored on its inode whenever we need to perform an operation
on the directory. This prevents simultaneous operations on any given
directory. 

Removing a directory requires us to (1) acquire a lock on its parent
and (2) lookup and open its inode. We perform (1) before (2) so 
by the time the second remover gets to lookup the dir's inode the
dir will already be removed from its parent. Thus, the second remover
will not see it and the race is prevented.

Adding to a directory follows the same outline, as do other operations.

>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process's current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?

No. We refuse to remove directory if (1) its inode's open_cnt is greater
than 1 (we open the inode before we remove it, so we cannot check for 
greater than 0) or (2) if there are files/dirs in it.

Condition (1) is violated if any process has the dir open and importantly
each process' working directory is an open dir. So, For each working
directory (1) is violated.

---- RATIONALE ----

>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.

By using an actual opened dir to represent the working directory we
make lookups for relative paths very quick since we only need to return
it from the thread struct. Furthermore, since the dir is opened we
prevent anyone from `remove`ing it.

			     BUFFER CACHE
			     ============

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

from `cache.c`:

enum cache_flags
  {
    USED = 0x1,
    ACCESSED = 0x2,
    DIRTY = 0x4,
    INIT = 0x8,
<<<<<<< Updated upstream
    READING_DISK = 0x10,
=======
    READING_DISK = 0xF,
>>>>>>> Stashed changes
  }; 

This enum is used in `struct cache_entry`s in order to distinguish
  which state the entry is in.

`used` means the cache_entry is in use.
`accessed` means it was accessed since the last clock sweep.
`dirty` means it's been written to since its last flush.
`init` means that the cache entry is fresh, requiring disk I/O
`reading_disk` means that it is currently being init'd by somebody else

struct cache_entry
  {
    block_sector_t sector;

    enum cache_flags flags;   
    int retain_cnt;
    int release_cnt;
    struct lock entry_lock;
    struct condition finished;
    struct hash_elem elem;
    uint8_t data[BLOCK_SECTOR_SIZE];
  };

This is what we store in our cache hashtable. It represents one
  cached sector.

`retain_cnt` is a count of clients currently reading/writing to this
  block.
`release_cnt` is a count of how many clients have un-retained.
(These two together define a reference-counted system for determining
whether an entry is safe to evict.)

`entry_lock` is a monitor for this struct's flags and release_cnt
`finished` is a condition variable that is triggered once the sector
  is read in from disk into this entry's store
`elem` is the elem for storage in the hash.
`data` is the actual sector data that represents the disk 

static struct hash cache_hash;

This is our sector cache.

static struct cache_entry *cache_entries;

This is a dynamically allocated array of cache_entries which stores
  as many entries as our cache was initialized with.

static int cache_size;

How many sectors we're allowed to cache

static int cache_clock_cursor; 

Where our clock hand points. This is used by the eviction algorithm.

static struct lock cache_lock;

This lock monitors the cache_hash. It's acquired before we look for
  an entry to evict and before we flush the cache. 


---- ALGORITHMS ----

>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.

Using a clock-hand, we sweep over the cache looking for entries similar
to our VM frame eviction algorithm. A cache entry can be evicted exactly
when:
- the entry is completely unused (i.e. on startup) 
OR all of:
- its lock is available (we try_acquire)
- it has not been accessed since last clock-sweep (ACCESSED bit)
- there are no outstanding references (i.e. retain_cnt == release_cnt)

Two sweep attempts are given for the ACCESSED bit above, as the hand
will clear entries as it sweeps over them. The last of these is the
most domain-specific, as operations on cache entries are lockless.
A cache entry is only guaranteed to be valid for an operation if
it has been retained, but not yet released, by the transactor.

>> C3: Describe your implementation of write-behind.

Our write-behind implementation uses a single thread that tries to 
write all N cache entries by sleeping in increments of 30 / N seconds,
seeing if its current cursor points to a dirty entry and, if so,
writes it to disk, before advancing its cursor and going back to
sleep. This way, we guarantee that the entire cache is synch'd
back to disk in case of a crash every 30 seconds, but it minimizes
any spiky interaction with the disk or the rest of the operating
system.

>> C4: Describe your implementation of read-ahead.

Our read-ahead implementation uses some fixed number of threads 
(in the current implementation, NUM_READAHEAD_THREADS = 3) that
all read from a cyclic buffer (of current size 16). New readahead
requests are put into the buffer and cause a cond_signal to
readahead_available, which is then hopefully serviced by one of
these threads. 

On wakeup, a readahead thread will find a suitable place to
put the requested sector in the cache (unless it's already there!)
and then start a disk I/O. Process threads that later show up
to read from the sectors will block on the cache entry's 
finished_reading condition, if needed, to finish the I/O.

---- SYNCHRONIZATION ----

>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?

As discussed above, active operations on cache buffer data have
a `retain' on the cache entry, but have not yet `release'd this
reference. A cache entry under no circumstances can be evicted 
unless retain_cnt == release_cnt. (Also, these counts themselves
are locked on read/write to prevent nonatomic write artifacts.)

>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?

When a block is evicted it is put into the  "WRITING_DISK" state.
If a request comes in for the block while it is in "WRITING_DISK" then
the requesting thread will be blocked on the "finished" cond variable.

Once the write finishes, the requesting thread will wake up and acquire
the lock (eventually). It will then check that the sector number of the
cache entry it just acquired is correct. If this is not the case then
it will trigger the standard cache-miss behavior and cache in the sector.

---- RATIONALE ----

>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.

Buffer caching is particularly useful for things that touch deep paths
a lot. If, for instance, we want to add files to a dir like /a/b/c/d/e/f
or perform lots of writes and reads in that location then our filesystem
will have to perform a full recursive lookup each time -- which requires
loading the inodes for each directory off disk -- and this is slow. The
buffer cache will probably keep them in memory and make the lookups very
fast. In general if we were to do something like random access into a
file that we open and close a lot then the buffer cache will speed it up
significantly -- for instance, a text editor could benefit.

Read-ahead is helpful for things which do sequential reads. One obvious 
example is a media server on the web. Streaming a video will typically 
require us to read several sequential sectors so read-ahead will 
start reading the next part of the video into memory before we need it.

Write-behind is helpful if we're doing lots of small writes to a file.
For instance, a text editor that implements rapid autosaving would
benefit from write-behind because it would not have to block for 
nearly as long on each write to disk so the autosaving would seem
much more seamless. 


			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students in future quarters?

>> Any other comments?
